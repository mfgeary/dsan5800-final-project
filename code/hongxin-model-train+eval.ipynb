{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d7279b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacremoses in d:\\anaconda3\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: click in d:\\anaconda3\\lib\\site-packages (from sacremoses) (8.1.7)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda3\\lib\\site-packages (from sacremoses) (4.64.1)\n",
      "Requirement already satisfied: regex in d:\\anaconda3\\lib\\site-packages (from sacremoses) (2022.7.9)\n",
      "Requirement already satisfied: joblib in d:\\anaconda3\\lib\\site-packages (from sacremoses) (1.2.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from click->sacremoses) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "794dc6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorForLanguageModeling\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "csv_path = '../data/gutenberg-homophone-errors.csv'  # Update this path\n",
    "data = pd.read_csv(csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c404b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>has_homophone</th>\n",
       "      <th>is_error</th>\n",
       "      <th>error_idx</th>\n",
       "      <th>error</th>\n",
       "      <th>correct_word</th>\n",
       "      <th>correct_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿the project gutenberg ebook of frankenstein; ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>33.0</td>\n",
       "      <td>know</td>\n",
       "      <td>no</td>\n",
       "      <td>﻿the project gutenberg ebook of frankenstein; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you may copy it, give it away or re-use it und...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>you may copy it, give it away or re-use it und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if you are not located in the united states,yo...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>18.0</td>\n",
       "      <td>wear</td>\n",
       "      <td>where</td>\n",
       "      <td>if you are not located in the united states,yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>petersburgh, dec. 11th, 17—.you will rejoice t...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>here</td>\n",
       "      <td>hear</td>\n",
       "      <td>petersburgh, dec. 11th, 17—.you will rejoice t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i arrived here yesterday, and my first task is...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i arrived here yesterday, and my first task is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  has_homophone  is_error  \\\n",
       "0  ﻿the project gutenberg ebook of frankenstein; ...           True      True   \n",
       "1  you may copy it, give it away or re-use it und...           True     False   \n",
       "2  if you are not located in the united states,yo...           True      True   \n",
       "3  petersburgh, dec. 11th, 17—.you will rejoice t...           True      True   \n",
       "4  i arrived here yesterday, and my first task is...           True     False   \n",
       "\n",
       "   error_idx error correct_word  \\\n",
       "0       33.0  know           no   \n",
       "1        NaN   NaN          NaN   \n",
       "2       18.0  wear        where   \n",
       "3        7.0  here         hear   \n",
       "4        NaN   NaN          NaN   \n",
       "\n",
       "                                    correct_sentence  \n",
       "0  ﻿the project gutenberg ebook of frankenstein; ...  \n",
       "1  you may copy it, give it away or re-use it und...  \n",
       "2  if you are not located in the united states,yo...  \n",
       "3  petersburgh, dec. 11th, 17—.you will rejoice t...  \n",
       "4  i arrived here yesterday, and my first task is...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58966292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to mask homophones\n",
    "def mask_homophones(row, mask_token='<mask>'):\n",
    "    words = row['sentences'].split()\n",
    "    if row['is_error'] and row['error_idx'] < len(words):\n",
    "        words[int(row['error_idx'])] = mask_token\n",
    "        return ' '.join(words)\n",
    "    return row['sentences']\n",
    "\n",
    "# Apply the function and prepare the datasets\n",
    "data['masked_sentences'] = data.apply(mask_homophones, axis=1)\n",
    "\n",
    "# Splitting the dataset\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-mlm-en-2048\")\n",
    "\n",
    "# Tokenize the sentences\n",
    "train_encodings = tokenizer(train_data['masked_sentences'].tolist(), truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_data['masked_sentences'].tolist(), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_data['masked_sentences'].tolist(), truncation=True, padding=True)\n",
    "\n",
    "# Data collator for dynamic masking\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ca3b9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class HomophoneDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "# Convert the tokenized sentences to the dataset\n",
    "train_dataset = HomophoneDataset(train_encodings)\n",
    "val_dataset = HomophoneDataset(val_encodings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87bc8f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\miran/.cache\\huggingface\\hub\\models--xlm-mlm-en-2048\\snapshots\\6eb6401a142611ae90f3d6bc606b97384f1c9961\\config.json\n",
      "Model config XLMConfig {\n",
      "  \"_name_or_path\": \"xlm-mlm-en-2048\",\n",
      "  \"architectures\": [\n",
      "    \"XLMWithLMHeadModel\"\n",
      "  ],\n",
      "  \"asm\": false,\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_index\": 0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"causal\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"emb_dim\": 2048,\n",
      "  \"embed_init_std\": 0.02209708691207961,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_index\": 1,\n",
      "  \"gelu_activation\": true,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder\": true,\n",
      "  \"lang_id\": 0,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mask_index\": 5,\n",
      "  \"mask_token_id\": 0,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"xlm\",\n",
      "  \"n_heads\": 16,\n",
      "  \"n_langs\": 1,\n",
      "  \"n_layers\": 12,\n",
      "  \"pad_index\": 2,\n",
      "  \"pad_token_id\": 2,\n",
      "  \"sinusoidal_embeddings\": false,\n",
      "  \"start_n_top\": 5,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"unk_index\": 3,\n",
      "  \"use_lang_emb\": true,\n",
      "  \"vocab_size\": 30145\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\miran/.cache\\huggingface\\hub\\models--xlm-mlm-en-2048\\snapshots\\6eb6401a142611ae90f3d6bc606b97384f1c9961\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing XLMWithLMHeadModel.\n",
      "\n",
      "Some weights of XLMWithLMHeadModel were not initialized from the model checkpoint at xlm-mlm-en-2048 and are newly initialized: ['transformer.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, Trainer, TrainingArguments\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"xlm-mlm-en-2048\")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee830e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 36476\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6840\n",
      "  Number of trainable parameters = 667119041\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea00db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def evaluate_model(model, tokenizer, data):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total, correct = 0, 0\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        masked_sentence = mask_homophones(row)\n",
    "        inputs = tokenizer(masked_sentence, return_tensors='pt')\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        predicted_token = tokenizer.decode(predictions[0]).split()[int(row['error_idx'])]\n",
    "        \n",
    "        if predicted_token == row['correct_word']:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = evaluate_model(model, tokenizer, test_data)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3177500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model after training\n",
    "model.save_pretrained('./trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b645a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "model = AutoModelForMaskedLM.from_pretrained('./trained_model')\n",
    "\n",
    "# Perform evaluation using the evaluate_model function as previously defined\n",
    "accuracy = evaluate_model(model, tokenizer, test_data)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
