{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Model to Correct Homophone Misue\n",
    "author: Marion Bauman\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our natural language processing model, we will be building a tool that corrects homophone misuse.\n",
    "\n",
    "Our model will compute the likelihood that a given word is correct, and if it is not, it will suggest a replacement word. This will be tested on a corpus of data including some intentional homophone misuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer_config.json: 100%|██████████| 29.0/29.0 [00:00<00:00, 1.95kB/s]\n",
      "Downloading vocab.txt: 100%|██████████| 213k/213k [00:00<00:00, 3.97MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 436k/436k [00:00<00:00, 13.7MB/s]\n",
      "Downloading config.json: 100%|██████████| 570/570 [00:00<00:00, 123kB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 436M/436M [00:07<00:00, 56.0MB/s] \n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForMaskedLM, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat GPT Prompt: Give me a list of lists in python of 100 sets of homophones\n",
    "homophones_list = [\n",
    "    [\"ate\", \"eight\"],\n",
    "    [\"bare\", \"bear\"],\n",
    "    [\"brake\", \"break\"],\n",
    "    [\"capital\", \"capitol\"],\n",
    "    [\"cell\", \"sell\"],\n",
    "    [\"cite\", \"site\", \"sight\"],\n",
    "    [\"complement\", \"compliment\"],\n",
    "    [\"desert\", \"dessert\"],\n",
    "    [\"die\", \"dye\"],\n",
    "    [\"flour\", \"flower\"],\n",
    "    [\"hear\", \"here\"],\n",
    "    [\"hour\", \"our\"],\n",
    "    [\"knight\", \"night\"],\n",
    "    [\"know\", \"no\"],\n",
    "    [\"mail\", \"male\"],\n",
    "    [\"meat\", \"meet\"],\n",
    "    [\"morning\", \"mourning\"],\n",
    "    [\"one\", \"won\"],\n",
    "    [\"pair\", \"pear\"],\n",
    "    [\"peace\", \"piece\"],\n",
    "    [\"principal\", \"principle\"],\n",
    "    [\"rain\", \"reign\", \"rein\"],\n",
    "    [\"right\", \"write\"],\n",
    "    [\"sea\", \"see\"],\n",
    "    [\"serial\", \"cereal\"],\n",
    "    [\"sole\", \"soul\"],\n",
    "    [\"stationary\", \"stationery\"],\n",
    "    [\"tail\", \"tale\"],\n",
    "    [\"threw\", \"through\"],\n",
    "    [\"to\", \"too\", \"two\"],\n",
    "    [\"weather\", \"whether\"],\n",
    "    [\"week\", \"weak\"],\n",
    "    [\"wear\", \"where\"],\n",
    "    [\"which\", \"witch\"],\n",
    "    [\"your\", \"you're\"],\n",
    "    [\"allowed\", \"aloud\"],\n",
    "    [\"board\", \"bored\"],\n",
    "    [\"brake\", \"break\"],\n",
    "    [\"capital\", \"capitol\"],\n",
    "    [\"compliment\", \"complement\"],\n",
    "    [\"desert\", \"dessert\"],\n",
    "    [\"dual\", \"duel\"],\n",
    "    [\"fair\", \"fare\"],\n",
    "    [\"genre\", \"jinja\"],\n",
    "    [\"hare\", \"hair\"],\n",
    "    [\"here\", \"hear\"],\n",
    "    [\"hoard\", \"horde\"],\n",
    "    [\"loan\", \"lone\"],\n",
    "    [\"pail\", \"pale\"],\n",
    "    [\"peak\", \"peek\", \"pique\"],\n",
    "    [\"profit\", \"prophet\"],\n",
    "    [\"role\", \"roll\"],\n",
    "    [\"root\", \"route\"],\n",
    "    [\"sail\", \"sale\"],\n",
    "    [\"scene\", \"seen\"],\n",
    "    [\"serial\", \"cereal\"],\n",
    "    [\"so\", \"sow\"],\n",
    "    [\"stare\", \"stair\"],\n",
    "    [\"steal\", \"steel\"],\n",
    "    [\"their\", \"there\", \"they're\"],\n",
    "    [\"throne\", \"thrown\"],\n",
    "    [\"vain\", \"vein\", \"vane\"],\n",
    "    [\"weak\", \"week\"],\n",
    "    [\"wood\", \"would\"],\n",
    "    [\"yew\", \"you\"],\n",
    "    [\"bridal\", \"bridle\"],\n",
    "    [\"cereal\", \"serial\"],\n",
    "    [\"chord\", \"cord\"],\n",
    "    [\"compliment\", \"complement\"],\n",
    "    [\"dew\", \"due\"],\n",
    "    [\"foul\", \"fowl\"],\n",
    "    [\"grate\", \"great\"],\n",
    "    [\"groan\", \"grown\"],\n",
    "    [\"heal\", \"heel\"],\n",
    "    [\"him\", \"hymn\"],\n",
    "    [\"lay\", \"lie\"],\n",
    "    [\"main\", \"mane\"],\n",
    "    [\"marry\", \"merry\"],\n",
    "    [\"mite\", \"might\"],\n",
    "    [\"moose\", \"mousse\"],\n",
    "    [\"mourn\", \"morn\"],\n",
    "    [\"peace\", \"piece\"],\n",
    "    [\"plum\", \"plumb\"],\n",
    "    [\"pour\", \"pore\"],\n",
    "    [\"rap\", \"wrap\"],\n",
    "    [\"scene\", \"seen\"],\n",
    "    [\"scent\", \"cent\", \"sent\"],\n",
    "    [\"serial\", \"cereal\"],\n",
    "    [\"shear\", \"sheer\"],\n",
    "    [\"soar\", \"sore\"],\n",
    "    [\"sow\", \"sew\"],\n",
    "    [\"stake\", \"steak\"],\n",
    "    [\"tide\", \"tied\"],\n",
    "    [\"toe\", \"tow\"],\n",
    "    [\"there\", \"their\", \"they're\"],\n",
    "    [\"waist\", \"waste\"],\n",
    "    [\"week\", \"weak\"],\n",
    "    [\"write\", \"right\", \"rite\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "gutenberg_homophone_data = pd.read_csv('../data/gutenberg-homophone-errors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"\"\"He doesn't no how to code.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', 'doesn', \"'\", 't', 'no', 'how', 'to', 'code', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenized_sentence = tokenizer.tokenize(test_sentence)\n",
    "print(tokenized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the list of lists\n",
    "homophones_list_flat = [item for sublist in homophones_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "PipelineException",
     "evalue": "No mask_token ([MASK]) found on the input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPipelineException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mariongeary/Library/Mobile Documents/com~apple~CloudDocs/Documents/grad_school/s1/dsan5800/final-project/dsan5800-final-project/code/marion-modeling-attempt.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mariongeary/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/grad_school/s1/dsan5800/final-project/dsan5800-final-project/code/marion-modeling-attempt.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mariongeary/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/grad_school/s1/dsan5800/final-project/dsan5800-final-project/code/marion-modeling-attempt.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m mask_filler \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39m\u001b[39mfill-mask\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbert-base-cased\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mariongeary/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/grad_school/s1/dsan5800/final-project/dsan5800-final-project/code/marion-modeling-attempt.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m mask_filler(tokenized_sentence, top_k\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/dsan5800/lib/python3.9/site-packages/transformers/pipelines/fill_mask.py:270\u001b[0m, in \u001b[0;36mFillMaskPipeline.__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    249\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m    Fill the masked token in the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39m        - **token_str** (`str`) -- The predicted token (to replace the masked one).\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    271\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, \u001b[39mlist\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(inputs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    272\u001b[0m         \u001b[39mreturn\u001b[39;00m outputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/dsan5800/lib/python3.9/site-packages/transformers/pipelines/base.py:1121\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[39mif\u001b[39;00m can_use_iterator:\n\u001b[1;32m   1118\u001b[0m     final_iterator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[1;32m   1119\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1120\u001b[0m     )\n\u001b[0;32m-> 1121\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(final_iterator)\n\u001b[1;32m   1122\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n\u001b[1;32m   1123\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/dsan5800/lib/python3.9/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[39m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[1;32m    125\u001b[0m processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(item, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[39m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dsan5800/lib/python3.9/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[39m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[1;32m    125\u001b[0m processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(item, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[39m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dsan5800/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/dsan5800/lib/python3.9/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/dsan5800/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/dsan5800/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/dsan5800/lib/python3.9/site-packages/transformers/pipelines/pt_utils.py:19\u001b[0m, in \u001b[0;36mPipelineDataset.__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, i):\n\u001b[1;32m     18\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[i]\n\u001b[0;32m---> 19\u001b[0m     processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess(item, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n\u001b[1;32m     20\u001b[0m     \u001b[39mreturn\u001b[39;00m processed\n",
      "File \u001b[0;32m~/anaconda3/envs/dsan5800/lib/python3.9/site-packages/transformers/pipelines/fill_mask.py:123\u001b[0m, in \u001b[0;36mFillMaskPipeline.preprocess\u001b[0;34m(self, inputs, return_tensors, tokenizer_kwargs, **preprocess_parameters)\u001b[0m\n\u001b[1;32m    120\u001b[0m     tokenizer_kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer(inputs, return_tensors\u001b[39m=\u001b[39mreturn_tensors, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtokenizer_kwargs)\n\u001b[0;32m--> 123\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mensure_exactly_one_mask_token(model_inputs)\n\u001b[1;32m    124\u001b[0m \u001b[39mreturn\u001b[39;00m model_inputs\n",
      "File \u001b[0;32m~/anaconda3/envs/dsan5800/lib/python3.9/site-packages/transformers/pipelines/fill_mask.py:112\u001b[0m, in \u001b[0;36mFillMaskPipeline.ensure_exactly_one_mask_token\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m     \u001b[39mfor\u001b[39;00m input_ids \u001b[39min\u001b[39;00m model_inputs[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 112\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ensure_exactly_one_mask_token(input_ids)\n",
      "File \u001b[0;32m~/anaconda3/envs/dsan5800/lib/python3.9/site-packages/transformers/pipelines/fill_mask.py:100\u001b[0m, in \u001b[0;36mFillMaskPipeline._ensure_exactly_one_mask_token\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m     98\u001b[0m numel \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mprod(masked_index\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m numel \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 100\u001b[0m     \u001b[39mraise\u001b[39;00m PipelineException(\n\u001b[1;32m    101\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfill-mask\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    102\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mbase_model_prefix,\n\u001b[1;32m    103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo mask_token (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mmask_token\u001b[39m}\u001b[39;00m\u001b[39m) found on the input\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    104\u001b[0m     )\n",
      "\u001b[0;31mPipelineException\u001b[0m: No mask_token ([MASK]) found on the input"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "mask_filler = pipeline(\"fill-mask\", \"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/mariongeary/Library/Mobile Documents/com~apple~CloudDocs/Documents/grad_school/s1/dsan5800/final-project/dsan5800-final-project/code/marion-modeling-attempt.ipynb Cell 10\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mariongeary/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/grad_school/s1/dsan5800/final-project/dsan5800-final-project/code/marion-modeling-attempt.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ts_full \u001b[39m=\u001b[39m ts_full\u001b[39m.\u001b[39mappend(testy[ts\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mariongeary/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/grad_school/s1/dsan5800/final-project/dsan5800-final-project/code/marion-modeling-attempt.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(ts_full)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mariongeary/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/grad_school/s1/dsan5800/final-project/dsan5800-final-project/code/marion-modeling-attempt.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mif\u001b[39;00m ts_full[ts] \u001b[39min\u001b[39;00m homophones_list_flat:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mariongeary/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/grad_school/s1/dsan5800/final-project/dsan5800-final-project/code/marion-modeling-attempt.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(ts_full[ts])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mariongeary/Library/Mobile%20Documents/com~apple~CloudDocs/Documents/grad_school/s1/dsan5800/final-project/dsan5800-final-project/code/marion-modeling-attempt.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     ts_full[ts] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m[MASK]\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "testy = test_sentence.split()\n",
    "outs = []\n",
    "for ts in range(0, len(testy)):\n",
    "    ts_full = testy.copy()[:ts+1]\n",
    "    print(ts_full)\n",
    "    if ts_full[ts] in homophones_list_flat:\n",
    "        print(ts_full[ts])\n",
    "        ts_full[ts] = '[MASK]'\n",
    "        ts_full = ' '.join(ts_full)\n",
    "        print(ts_full)\n",
    "        print(mask_filler(ts_full, top_k=3))\n",
    "        outs.append(mask_filler(ts_full, top_k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.9814466238021851,\n",
       "   'token': 119,\n",
       "   'token_str': '.',\n",
       "   'sequence': \"He doesn't.\"},\n",
       "  {'score': 0.009747138246893883,\n",
       "   'token': 132,\n",
       "   'token_str': ';',\n",
       "   'sequence': \"He doesn't ;\"},\n",
       "  {'score': 0.00484459986910224,\n",
       "   'token': 106,\n",
       "   'token_str': '!',\n",
       "   'sequence': \"He doesn't!\"},\n",
       "  {'score': 0.003609249135479331,\n",
       "   'token': 136,\n",
       "   'token_str': '?',\n",
       "   'sequence': \"He doesn't?\"},\n",
       "  {'score': 0.0001153292105300352,\n",
       "   'token': 1232,\n",
       "   'token_str': '...',\n",
       "   'sequence': \"He doesn't...\"}],\n",
       " [{'score': 0.7354617714881897,\n",
       "   'token': 119,\n",
       "   'token_str': '.',\n",
       "   'sequence': \"He doesn't no how.\"},\n",
       "  {'score': 0.1854487657546997,\n",
       "   'token': 136,\n",
       "   'token_str': '?',\n",
       "   'sequence': \"He doesn't no how?\"},\n",
       "  {'score': 0.055269792675971985,\n",
       "   'token': 106,\n",
       "   'token_str': '!',\n",
       "   'sequence': \"He doesn't no how!\"},\n",
       "  {'score': 0.01971513405442238,\n",
       "   'token': 132,\n",
       "   'token_str': ';',\n",
       "   'sequence': \"He doesn't no how ;\"},\n",
       "  {'score': 0.0010626193834468722,\n",
       "   'token': 1232,\n",
       "   'token_str': '...',\n",
       "   'sequence': \"He doesn't no how...\"}]]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsan5800",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
