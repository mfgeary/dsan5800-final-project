{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacremoses in /Users/Austin/opt/anaconda3/envs/torch/lib/python3.10/site-packages (0.1.1)\n",
      "Requirement already satisfied: regex in /Users/Austin/opt/anaconda3/envs/torch/lib/python3.10/site-packages (from sacremoses) (2022.10.31)\n",
      "Requirement already satisfied: click in /Users/Austin/opt/anaconda3/envs/torch/lib/python3.10/site-packages (from sacremoses) (8.1.3)\n",
      "Requirement already satisfied: joblib in /Users/Austin/opt/anaconda3/envs/torch/lib/python3.10/site-packages (from sacremoses) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /Users/Austin/opt/anaconda3/envs/torch/lib/python3.10/site-packages (from sacremoses) (4.65.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U -q sacremoses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homophone List\n",
    "\n",
    "This needs to be expanded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "homophones_list = [\n",
    "    ['accessary', 'accessory'],\n",
    "    ['ad', 'add'],\n",
    "    ['ail', 'ale'],\n",
    "    ['air', 'heir'],\n",
    "    ['aisle', \"I'll\", 'isle'],\n",
    "    ['all', 'awl'],\n",
    "    ['allowed', 'aloud'],\n",
    "    ['altar', 'alter'],\n",
    "    ['arc', 'ark'],\n",
    "    ['ant', 'aunt'],\n",
    "    ['ate', 'eight'],\n",
    "    ['auger', 'augur'],\n",
    "    ['auk', 'orc'],\n",
    "    ['aural', 'oral'],\n",
    "    ['away', 'aweigh'],\n",
    "    ['aw', 'awe'],\n",
    "    ['ore', 'oar', 'or'],\n",
    "    ['axel', 'axle'],\n",
    "    ['aye', 'eye', 'I'],\n",
    "    ['bail', 'bale'],\n",
    "    ['bait', 'bate'],\n",
    "    ['baize', 'bays'],\n",
    "    ['bald', 'bawled'],\n",
    "    ['ball', 'bawl'],\n",
    "    ['band', 'banned'],\n",
    "    ['bard', 'barred'],\n",
    "    ['bare', 'bear'],\n",
    "    ['bark', 'barque'],\n",
    "    ['baron', 'barren'],\n",
    "    ['base', 'bass'],\n",
    "    ['based', 'baste'],\n",
    "    ['bazaar', 'bizarre'],\n",
    "    ['be', 'bee'],\n",
    "    ['bay', 'bey'],\n",
    "    ['beach', 'beech'],\n",
    "    ['bean', 'been'],\n",
    "    ['beat', 'beet'],\n",
    "    ['beau', 'bow'],\n",
    "    ['beer', 'bier'],\n",
    "    ['bel', 'bell', 'belle'],\n",
    "    ['berry', 'bury'],\n",
    "    ['berth', 'birth'],\n",
    "    ['bight', 'bite', 'byte'],\n",
    "    ['billed', 'build'],\n",
    "    ['bitten', 'bittern'],\n",
    "    ['blew', 'blue'],\n",
    "    ['bloc', 'block', 'bloque'],\n",
    "    ['boar', 'bore'],\n",
    "    ['board', 'bored'],\n",
    "    ['boarder', 'border'],\n",
    "    ['bold', 'bowled'],\n",
    "    ['boos', 'booze'],\n",
    "    ['born', 'borne'],\n",
    "    ['bough', 'bow'],\n",
    "    ['boy', 'buoy'],\n",
    "    ['brae', 'bray'],\n",
    "    ['braid', 'brayed'],\n",
    "    ['braise', 'brays', 'braze'],\n",
    "    ['brake', 'break'],\n",
    "    ['bread', 'bred'],\n",
    "    ['brews', 'bruise'],\n",
    "    ['bridal', 'bridle'],\n",
    "    ['broach', 'brooch'],\n",
    "    ['bur', 'burr', 'brr'],\n",
    "    ['but', 'butt'],\n",
    "    ['buy', 'by', 'bye'],\n",
    "    ['buyer', 'byre'],\n",
    "    ['calendar', 'calender'],\n",
    "    ['call', 'caul'],\n",
    "    ['canvas', 'canvass'],\n",
    "    ['cast', 'caste'],\n",
    "    ['caster', 'castor'],\n",
    "    ['caught', 'court'],\n",
    "    ['caw', 'core', 'corps'],\n",
    "    ['cede', 'seed'],\n",
    "    ['ceiling', 'sealing'],\n",
    "    ['cell', 'sell'],\n",
    "    ['censer', 'censor', 'sensor'],\n",
    "    ['cent', 'scent', 'sent'],\n",
    "    ['cereal', 'serial'],\n",
    "    ['cheap', 'cheep'],\n",
    "    ['check', 'cheque'],\n",
    "    ['choir', 'quire'],\n",
    "    ['chord', 'cord'],\n",
    "    ['cite', 'sight', 'site'],\n",
    "    ['clack', 'claque'],\n",
    "    ['clew', 'clue'],\n",
    "    ['climb', 'clime'],\n",
    "    ['close', 'cloze'],\n",
    "    ['coal', 'kohl'],\n",
    "    ['coarse', 'course'],\n",
    "    ['coign', 'coin'],\n",
    "    ['colonel', 'kernel'],\n",
    "    ['complacent', 'complaisant'],\n",
    "    ['complement', 'compliment'],\n",
    "    ['coo', 'coup'],\n",
    "    ['cops', 'copse'],\n",
    "    ['council', 'counsel'],\n",
    "    ['cousin', 'cozen'],\n",
    "    ['creak', 'creek'],\n",
    "    ['crews', 'cruise'],\n",
    "    ['cue', 'kyu', 'queue'],\n",
    "    ['curb', 'kerb'],\n",
    "    ['currant', 'current'],\n",
    "    ['cymbol', 'symbol'],\n",
    "    ['dam', 'damn'],\n",
    "    ['days', 'daze'],\n",
    "    ['dear', 'deer'],\n",
    "    ['descent', 'dissent'],\n",
    "    ['desert', 'dessert'],\n",
    "    ['deviser', 'divisor'],\n",
    "    ['dew', 'due'],\n",
    "    ['die', 'dye'],\n",
    "    ['discreet', 'discrete'],\n",
    "    ['doe', 'doh', 'dough'],\n",
    "    ['done', 'dun'],\n",
    "    ['douse', 'dowse'],\n",
    "    ['draft', 'draught'],\n",
    "    ['dual', 'duel'],\n",
    "    ['earn', 'urn'],\n",
    "    ['eery', 'eyrie'],\n",
    "    ['ewe', 'yew', 'you'],\n",
    "    ['faint', 'feint'],\n",
    "    ['fah', 'far'],\n",
    "    ['fair', 'fare'],\n",
    "    ['fairy', 'ferry'],\n",
    "    ['fate', 'fete'],\n",
    "    ['farther', 'father'],\n",
    "    ['faun', 'fawn'],\n",
    "    ['faze', 'phase'],\n",
    "    ['fay', 'fey'],\n",
    "    ['feat', 'feet'],\n",
    "    ['ferrule', 'ferule'],\n",
    "    ['few', 'phew'],\n",
    "    ['fie', 'phi'],\n",
    "    ['file', 'phial'],\n",
    "    ['find', 'fined'],\n",
    "    ['fir', 'fur'],\n",
    "    ['fizz', 'phiz'],\n",
    "    ['flair', 'flare'],\n",
    "    ['flaw', 'floor'],\n",
    "    ['flea', 'flee'],\n",
    "    ['flex', 'flecks'],\n",
    "    ['flew', 'flu', 'flue'],\n",
    "    ['floe', 'flow'],\n",
    "    ['flour', 'flower'],\n",
    "    ['for', 'fore', 'four'],\n",
    "    ['foreword', 'forward'],\n",
    "    ['fort', 'fought'],\n",
    "    ['forth', 'fourth'],\n",
    "    ['foul', 'fowl'],\n",
    "    ['franc', 'frank'],\n",
    "    ['freeze', 'frieze'],\n",
    "    ['friar', 'fryer'],\n",
    "    ['furs', 'furze'],\n",
    "    ['gait', 'gate'],\n",
    "    ['galipot', 'gallipot'],\n",
    "    ['gamble', 'gambol'],\n",
    "    ['gallop', 'galop'],\n",
    "    ['gays', 'gaze'],\n",
    "    ['genes', 'jeans'],\n",
    "    ['gild', 'guild'],\n",
    "    ['gilt', 'guilt'],\n",
    "    ['giro', 'gyro'],\n",
    "    ['gnaw', 'nor'],\n",
    "    ['gneiss', 'nice'],\n",
    "    ['gorilla', 'guerilla'],\n",
    "    ['grate', 'great'],\n",
    "    ['greave', 'grieve'],\n",
    "    ['greys', 'graze'],\n",
    "    ['grisly', 'grizzly'],\n",
    "    ['groan', 'grown'],\n",
    "    ['guessed', 'guest'],\n",
    "    ['hail', 'hale'],\n",
    "    ['hair', 'hare'],\n",
    "    ['hall', 'haul'],\n",
    "    ['hangar', 'hanger'],\n",
    "    ['hart', 'heart'],\n",
    "    ['haw', 'hoar', 'whore'],\n",
    "    ['hay', 'hey'],\n",
    "    ['heal', 'heel', \"he'll\"],\n",
    "    ['here', 'hear'],\n",
    "    ['heard', 'herd'],\n",
    "    [\"he'd\", 'heed'],\n",
    "    ['heroin', 'heroine'],\n",
    "    ['hew', 'hue'],\n",
    "    ['hi', 'high'],\n",
    "    ['higher', 'hire'],\n",
    "    ['him', 'hymn'],\n",
    "    ['ho', 'hoe'],\n",
    "    ['hoard', 'horde'],\n",
    "    ['hoarse', 'horse'],\n",
    "    ['holey', 'holy', 'wholly'],\n",
    "    ['hour', 'our'],\n",
    "    ['idle', 'idol'],\n",
    "    ['in', 'inn'],\n",
    "    ['indict', 'indite'],\n",
    "    [\"it's\", 'its'],\n",
    "    ['jewel', 'joule', 'juul'],\n",
    "    ['key', 'quay'],\n",
    "    ['knave', 'nave'],\n",
    "    ['knead', 'need'],\n",
    "    ['knew', 'new'],\n",
    "    ['knight', 'night'],\n",
    "    ['knit', 'nit'],\n",
    "    ['knob', 'nob'],\n",
    "    ['knock', 'nock'],\n",
    "    ['knot', 'not'],\n",
    "    ['know', 'no'],\n",
    "    ['knows', 'nose'],\n",
    "    ['laager', 'lager'],\n",
    "    ['lac', 'lack'],\n",
    "    ['lade', 'laid'],\n",
    "    ['lain', 'lane'],\n",
    "    ['lam', 'lamb'],\n",
    "    ['laps', 'lapse'],\n",
    "    ['larva', 'lava'],\n",
    "    ['lase', 'laze'],\n",
    "    ['law', 'lore'],\n",
    "    ['lay', 'ley'],\n",
    "    ['lea', 'lee'],\n",
    "    ['leach', 'leech'],\n",
    "    ['lead', 'led'],\n",
    "    ['leak', 'leek'],\n",
    "    ['lean', 'lien'],\n",
    "    ['lessen', 'lesson'],\n",
    "    ['levee', 'levy'],\n",
    "    ['liar', 'lyre'],\n",
    "    ['licence', 'license'],\n",
    "    ['licker', 'liquor'],\n",
    "    ['lie', 'lye'],\n",
    "    ['lieu', 'loo'],\n",
    "    ['links', 'lynx'],\n",
    "    ['lo', 'low'],\n",
    "    ['load', 'lode'],\n",
    "    ['loan', 'lone'],\n",
    "    ['locks', 'lox'],\n",
    "    ['loop', 'loupe'],\n",
    "    ['loot', 'lute'],\n",
    "    ['made', 'maid'],\n",
    "    ['mail', 'male'],\n",
    "    ['main', 'mane'],\n",
    "    ['maize', 'maze'],\n",
    "    ['mall', 'maul'],\n",
    "    ['manna', 'manner'],\n",
    "    ['mantel', 'mantle'],\n",
    "    ['mare', 'mayor'],\n",
    "    ['mark', 'marque'],\n",
    "    ['marshal', 'martial'],\n",
    "    ['marten', 'martin'],\n",
    "    ['mask', 'masque'],\n",
    "    ['maw', 'more'],\n",
    "    ['me', 'mi'],\n",
    "    ['mean', 'mien'],\n",
    "    ['meat', 'meet', 'mete'],\n",
    "    ['medal', 'meddle'],\n",
    "    ['metal', 'mettle'],\n",
    "    ['meter', 'metre'],\n",
    "    ['might', 'mite'],\n",
    "    ['miner', 'minor', 'mynah'],\n",
    "    ['mind', 'mined'],\n",
    "    ['missed', 'mist'],\n",
    "    ['moat', 'mote'],\n",
    "    ['mode', 'mowed'],\n",
    "    ['moor', 'more'],\n",
    "    ['moose', 'mousse'],\n",
    "    ['morning', 'mourning'],\n",
    "    ['muscle', 'mussel'],\n",
    "    ['naval', 'navel'],\n",
    "    ['nay', 'neigh'],\n",
    "    ['nigh', 'nye'],\n",
    "    ['none', 'nun'],\n",
    "    ['od', 'odd'],\n",
    "    ['ode', 'owed'],\n",
    "    ['oh', 'owe'],\n",
    "    ['one', 'won'],\n",
    "    ['packed', 'pact'],\n",
    "    ['packs', 'pax'],\n",
    "    ['pail', 'pale'],\n",
    "    ['pain', 'pane'],\n",
    "    ['pair', 'pare', 'pear'],\n",
    "    ['palate', 'palette', 'pallet'],\n",
    "    ['pascal', 'paschal'],\n",
    "    ['paten', 'patten', 'pattern'],\n",
    "    ['pause', 'paws', 'pores', 'pours'],\n",
    "    ['peace', 'piece'],\n",
    "    ['peak', 'peek', 'pique', 'peke'],\n",
    "    ['pea', 'pee'],\n",
    "    ['peal', 'peel'],\n",
    "    ['pearl', 'purl'],\n",
    "    ['pedal', 'peddle'],\n",
    "    ['peer', 'pier'],\n",
    "    ['pi', 'pie'],\n",
    "    ['pica', 'pika'],\n",
    "    ['place', 'plaice'],\n",
    "    ['plain', 'plane'],\n",
    "    ['pleas', 'please'],\n",
    "    ['pole', 'poll'],\n",
    "    ['plum', 'plumb'],\n",
    "    ['poof', 'pouffe'],\n",
    "    ['practice', 'practise'],\n",
    "    ['praise', 'prays', 'preys'],\n",
    "    ['principal', 'principle'],\n",
    "    ['profit', 'prophet'],\n",
    "    ['quarts', 'quartz'],\n",
    "    ['quean', 'queen'],\n",
    "    ['rain', 'reign', 'rein'],\n",
    "    ['raise', 'rays', 'raze'],\n",
    "    ['rap', 'wrap'],\n",
    "    ['raw', 'roar'],\n",
    "    ['read', 'reed'],\n",
    "    ['read', 'red'],\n",
    "    ['real', 'reel'],\n",
    "    ['reek', 'wreak'],\n",
    "    ['rest', 'wrest'],\n",
    "    ['retch', 'wretch'],\n",
    "    ['review', 'revue'],\n",
    "    ['rheum', 'room'],\n",
    "    ['right', 'rite', 'wright', 'write'],\n",
    "    ['ring', 'wring'],\n",
    "    ['road', 'rode'],\n",
    "    ['roe', 'row'],\n",
    "    ['role', 'roll'],\n",
    "    ['roo', 'roux', 'rue'],\n",
    "    ['rood', 'rude'],\n",
    "    ['root', 'route'],\n",
    "    ['rose', 'rows'],\n",
    "    ['rota', 'rotor'],\n",
    "    ['rote', 'wrote'],\n",
    "    ['rough', 'ruff'],\n",
    "    ['rouse', 'rows'],\n",
    "    ['rung', 'wrung'],\n",
    "    ['rye', 'wry'],\n",
    "    ['saver', 'savour'],\n",
    "    ['scull', 'skull'],\n",
    "    ['spade', 'spayed'],\n",
    "    ['sale', 'sail'],\n",
    "    ['sane', 'seine'],\n",
    "    ['satire', 'satyr'],\n",
    "    ['sauce', 'source'],\n",
    "    ['saw', 'soar', 'sore'],\n",
    "    ['scene', 'seen'],\n",
    "    ['sea', 'see'],\n",
    "    ['seam', 'seem'],\n",
    "    ['sear', 'seer', 'sere'],\n",
    "    ['seas', 'sees', 'seize'],\n",
    "    ['shake', 'sheikh'],\n",
    "    ['sew', 'so', 'sow'],\n",
    "    ['shear', 'sheer'],\n",
    "    ['shoe', 'shoo'],\n",
    "    ['sic', 'sick'],\n",
    "    ['side', 'sighed'],\n",
    "    ['sign', 'sine'],\n",
    "    ['sink', 'synch'],\n",
    "    ['slay', 'sleigh'],\n",
    "    ['sloe', 'slow'],\n",
    "    ['sole', 'soul'],\n",
    "    ['some', 'sum'],\n",
    "    ['son', 'sun'],\n",
    "    ['sort', 'sought'],\n",
    "    ['spa', 'spar'],\n",
    "    ['staid', 'stayed'],\n",
    "    ['stair', 'stare'],\n",
    "    ['stake', 'steak'],\n",
    "    ['stalk', 'stork'],\n",
    "    ['stationary', 'stationery'],\n",
    "    ['steal', 'steel'],\n",
    "    ['stile', 'style'],\n",
    "    ['storey', 'story'],\n",
    "    ['straight', 'strait'],\n",
    "    ['sweet', 'suite'],\n",
    "    ['swat', 'swot'],\n",
    "    ['tacks', 'tax'],\n",
    "    ['tale', 'tail'],\n",
    "    ['talk', 'torque'],\n",
    "    ['tare', 'tear'],\n",
    "    ['taught', 'taut', 'tort'],\n",
    "    ['te', 'tea', 'tee', 't', 'ti'],\n",
    "    ['team', 'teem'],\n",
    "    ['tear', 'tier'],\n",
    "    ['teas', 'tease'],\n",
    "    ['terce', 'terse'],\n",
    "    ['tern', 'turn'],\n",
    "    ['there', 'their', \"they're\"],\n",
    "    ['threw', 'through', 'thru'],\n",
    "    ['throes', 'throws'],\n",
    "    ['throne', 'thrown'],\n",
    "    ['thyme', 'time'],\n",
    "    ['tic', 'tick'],\n",
    "    ['tide', 'tied'],\n",
    "    ['tire', 'tyre'],\n",
    "    ['to', 'too', 'two'],\n",
    "    ['toad', 'toed', 'towed'],\n",
    "    ['told', 'tolled'],\n",
    "    ['tole', 'toll'],\n",
    "    ['ton', 'tun'],\n",
    "    ['tor', 'tore'],\n",
    "    ['tough', 'tuff'],\n",
    "    ['troop', 'troupe'],\n",
    "    ['tuba', 'tuber'],\n",
    "    ['vain', 'vane', 'vein'],\n",
    "    ['vale', 'veil'],\n",
    "    ['vial', 'vile'],\n",
    "    ['vice', 'vise'],\n",
    "    ['wade', 'weighed'],\n",
    "    ['weak', 'week'],\n",
    "    ['we', 'wee', 'whee'],\n",
    "    ['way', 'weigh', 'whey'],\n",
    "    ['wax', 'whacks'],\n",
    "    ['wart', 'wort'],\n",
    "    ['watt', 'what'],\n",
    "    ['warn', 'worn'],\n",
    "    ['ware', 'wear', 'where'],\n",
    "    ['war', 'wore'],\n",
    "    ['wall', 'waul'],\n",
    "    ['waive', 'wave'],\n",
    "    ['wait', 'weight'],\n",
    "    ['wail', 'wale', 'whale'],\n",
    "    ['wain', 'wane'],\n",
    "    [\"we'd\", 'weed'],\n",
    "    ['weal', \"we'll\", 'wheel'],\n",
    "    ['wean', 'ween'],\n",
    "    ['weather', 'whether'],\n",
    "    ['weaver', 'weever'],\n",
    "    ['weir', \"we're\"],\n",
    "    ['were', 'whirr'],\n",
    "    ['wet', 'whet'],\n",
    "    ['wheald', 'wheeled'],\n",
    "    ['which', 'witch'],\n",
    "    ['whig', 'wig'],\n",
    "    ['while', 'wile'],\n",
    "    ['whine', 'wine'],\n",
    "    ['whirl', 'whorl'],\n",
    "    ['whirled', 'world'],\n",
    "    ['whit', 'wit'],\n",
    "    ['white', 'wight'],\n",
    "    [\"who's\", 'whose'],\n",
    "    ['woe', 'whoa'],\n",
    "    ['wood', 'would'],\n",
    "    ['yaw', 'yore', 'your', \"you're\"],\n",
    "    ['yoke', 'yolk'],\n",
    "    [\"you'll\", 'yule']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model\n",
    "\n",
    "Bert has been working decently well for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Austin/opt/anaconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the model and tokenizer\n",
    "fill_mask = pipeline('fill-mask', model='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect!\n",
      "Top result:  won\n",
      "Top result score:  0.704522430896759\n"
     ]
    }
   ],
   "source": [
    "# Create input string\n",
    "input_string = \"Michigan one the football game against Ohio State!\"\n",
    "\n",
    "# Select homophone\n",
    "target_homophone = \"one\"\n",
    "\n",
    "# Get homophone options\n",
    "homophone_options = [homophone for homophone in homophones_list if target_homophone in homophone]\n",
    "\n",
    "# Replace homophone with mask token\n",
    "input_string = input_string.replace(target_homophone, fill_mask.tokenizer.mask_token)\n",
    "\n",
    "# Get results\n",
    "results = fill_mask(input_string)\n",
    "\n",
    "# Token string dict\n",
    "token_string_dict = {}\n",
    "\n",
    "# Get top results\n",
    "for result in results:\n",
    "   token_string_dict[result[\"token_str\"]] = result[\"score\"]\n",
    "\n",
    "# Sort results\n",
    "sorted_results = sorted(token_string_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Find top homophone in results\n",
    "homophone_results = [result for result in sorted_results if result[0] in homophone_options[0]]\n",
    "\n",
    "if homophone_results[0][0] == target_homophone:\n",
    "    print(\"Correct!\")\n",
    "else:\n",
    "    print(\"Incorrect!\")\n",
    "    print(\"Top result: \", homophone_results[0][0])\n",
    "    print(\"Top result score: \", homophone_results[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that can check a sentence that only contains one homophone\n",
    "def one_homophone_checker(input_string, homophones_list=homophones_list, score_threshold=0):\n",
    "    # Lowering the input string\n",
    "    input_string = input_string.lower()\n",
    "\n",
    "    # Flatten homophones list\n",
    "    all_homophones = [\n",
    "        word for homophone_set in homophones_list for word in homophone_set\n",
    "    ]\n",
    "\n",
    "    # Find homophones in input string\n",
    "    target_homophone = list(set(input_string.split(\" \")).intersection(set(all_homophones)))\n",
    "    print(target_homophone)\n",
    "\n",
    "    # If there are no homophones in the sentence, return the NA dataframe\n",
    "    if len(target_homophone) < 1:\n",
    "        output_df = pd.DataFrame(\n",
    "            {\n",
    "                \"sentence\": input_string,\n",
    "                \"has_homophone\": False,\n",
    "                \"is_error\": None,\n",
    "                \"error_idx\": None,\n",
    "                \"error\": None,\n",
    "                \"correct_word\": None,\n",
    "                \"correct_sentence\": None,\n",
    "            }, index=[0]\n",
    "        )\n",
    "        return output_df\n",
    "\n",
    "    else:\n",
    "        target_homophone = target_homophone[0]\n",
    "\n",
    "    # Get all homophone options from homophones list\n",
    "    homophone_options = [homophone for homophone in homophones_list if target_homophone in homophone]\n",
    "\n",
    "    # Replace homophone with mask token\n",
    "    # CANNOT HANDLE MULTIPLE HOMOPHONES IN ONE SENTENCE\n",
    "    masked_string = ' '.join([word if word != target_homophone else fill_mask.tokenizer.mask_token for word in input_string.split(\" \")])\n",
    "    print(masked_string)\n",
    "    \n",
    "    # Get results\n",
    "    results = fill_mask(masked_string, top_k=20)\n",
    "\n",
    "    # Token string dict\n",
    "    token_string_dict = {}\n",
    "\n",
    "    # Get top results and their score\n",
    "    for result in results:\n",
    "        try:\n",
    "            token_string_dict[result[\"token_str\"]] = result[\"score\"]\n",
    "        except TypeError:\n",
    "            print(result)\n",
    "\n",
    "    # Sort results\n",
    "    sorted_results = sorted(token_string_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Find top homophone in results\n",
    "    homophone_results = [result for result in sorted_results if result[0] in homophone_options[0]]\n",
    "    print(homophone_results)\n",
    "    \n",
    "    # If the top result is the target homophone, return the original sentence as it is correct\n",
    "    if homophone_results[0][0] == target_homophone:\n",
    "        final_sentence = input_string\n",
    "        is_error = False\n",
    "        correct_word = None\n",
    "        error_idx = None\n",
    "        error = None\n",
    "\n",
    "    else:\n",
    "        # If the top result is not the target homophone, check how many options it found\n",
    "        # If multiple options:\n",
    "        if len(homophone_results) > 1:\n",
    "\n",
    "            # Check the difference between the top two results\n",
    "            score_diff = homophone_results[0][1] - homophone_results[1][1]\n",
    "\n",
    "            # If the difference is greater than the threshold, return the top result\n",
    "            if score_diff > score_threshold:\n",
    "                error_idx = input_string.split(\" \").index(target_homophone)\n",
    "                error = target_homophone\n",
    "                final_sentence = input_string.replace(target_homophone, homophone_results[0][0])\n",
    "                correct_word = homophone_results[0][0]\n",
    "                is_error = True\n",
    "        \n",
    "        # If the difference is less than the threshold, return the original sentence\n",
    "        else:\n",
    "            is_error = True\n",
    "            error_idx = input_string.split(\" \").index(target_homophone)\n",
    "            final_sentence = input_string.replace(target_homophone, homophone_results[0][0])\n",
    "            correct_word = homophone_results[0][0]\n",
    "            error = target_homophone\n",
    "\n",
    "    # Create output dataframe that matches our test data\n",
    "    output_df = pd.DataFrame(\n",
    "            {\n",
    "                \"sentence\": input_string,\n",
    "                \"has_homophone\": True,\n",
    "                \"is_error\": is_error,\n",
    "                \"error_idx\": error_idx,\n",
    "                \"error\": error,\n",
    "                \"correct_word\": correct_word,\n",
    "                \"correct_sentence\": final_sentence,\n",
    "            }, index=[0]\n",
    "        )\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to']\n",
      "at lunch today, i had way [MASK] much food!\n",
      "[('too', 0.9997673630714417), ('to', 4.6690133785887156e-06)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>has_homophone</th>\n",
       "      <th>is_error</th>\n",
       "      <th>error_idx</th>\n",
       "      <th>error</th>\n",
       "      <th>correct_word</th>\n",
       "      <th>correct_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>at lunch today, i had way to much food!</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>to</td>\n",
       "      <td>too</td>\n",
       "      <td>at lunch tooday, i had way too much food!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  sentence  has_homophone  is_error  \\\n",
       "0  at lunch today, i had way to much food!           True      True   \n",
       "\n",
       "   error_idx error correct_word                           correct_sentence  \n",
       "0          6    to          too  at lunch tooday, i had way too much food!  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_string = \"At lunch today, I had way to much food!\"\n",
    "\n",
    "one_homophone_checker(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one']\n",
      "michigan [MASK] the game against ohio state!\n",
      "[('won', 0.7407358884811401)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>has_homophone</th>\n",
       "      <th>is_error</th>\n",
       "      <th>error_idx</th>\n",
       "      <th>error</th>\n",
       "      <th>correct_word</th>\n",
       "      <th>correct_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>michigan one the game against ohio state!</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>won</td>\n",
       "      <td>michigan won the game against ohio state!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    sentence  has_homophone  is_error  \\\n",
       "0  michigan one the game against ohio state!           True      True   \n",
       "\n",
       "   error_idx error correct_word                           correct_sentence  \n",
       "0          1   one          won  michigan won the game against ohio state!  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_string = \"Michigan one the game against Ohio State!\"\n",
    "\n",
    "one_homophone_checker(input_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEXT STEPS: MAKE SENTENCES LIKE THIS WORK WITH MULTIPLE ERRORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you', 'waist', 'scene']\n",
      "have [MASK] scene my new waist of money?\n",
      "[('you', 0.3468347489833832)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>has_homophone</th>\n",
       "      <th>is_error</th>\n",
       "      <th>error_idx</th>\n",
       "      <th>error</th>\n",
       "      <th>correct_word</th>\n",
       "      <th>correct_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>have you scene my new waist of money?</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>have you scene my new waist of money?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                sentence  has_homophone  is_error error_idx  \\\n",
       "0  have you scene my new waist of money?           True     False      None   \n",
       "\n",
       "  error correct_word                       correct_sentence  \n",
       "0  None         None  have you scene my new waist of money?  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_string = \"Have you scene my new waist of money?\"\n",
    "\n",
    "one_homophone_checker(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Function that can check a sentence that has multiple homophones\n",
    "def homophone_checker(input_string, homophones_list=homophones_list, score_threshold=0):\n",
    "    \n",
    "    # Final output sentence \n",
    "    total_sentence = input_string\n",
    "\n",
    "    # Lowering the input string\n",
    "    input_string = input_string.lower()\n",
    "    input_string_list = input_string.split(\" \")\n",
    "    \n",
    "    # Flatten homophones list\n",
    "    all_homophones = [\n",
    "        word for homophone_set in homophones_list for word in homophone_set\n",
    "    ]\n",
    "\n",
    "    # Find homophones in input string\n",
    "    target_homophones = [(word, i) for i, word in enumerate(input_string_list) if list(set([word]).intersection(set(all_homophones)))]\n",
    "    # print(target_homophones)\n",
    "\n",
    "    # If there are no homophones in the sentence, return the NA dataframe\n",
    "    if len(target_homophones) < 1:\n",
    "        output_df = pd.DataFrame(\n",
    "            {\n",
    "                \"sentence\": input_string,\n",
    "                \"has_homophone\": False,\n",
    "                \"is_error\": None,\n",
    "                \"error_idx\": None,\n",
    "                \"error\": None,\n",
    "                \"correct_word\": None,\n",
    "                \"correct_sentence\": None,\n",
    "            }, index=[0]\n",
    "        )\n",
    "        return output_df\n",
    "\n",
    "    else:\n",
    "        final_sentence, is_error, correct_word, error_idx, error = [], [], [], [], []\n",
    "\n",
    "\n",
    "        for target_homophone_tuple in tqdm(target_homophones):\n",
    "            target_homophone = target_homophone_tuple[0]\n",
    "            target_homophone_idx = target_homophone_tuple[1]\n",
    "\n",
    "            input_string_list = input_string.split(\" \")\n",
    "            \n",
    "            # Get all homophone options from homophones list\n",
    "            homophone_options = [homophone for homophone in homophones_list if target_homophone in homophone]\n",
    "\n",
    "            # Replace homophone with mask token\n",
    "            input_string_list[target_homophone_idx] = fill_mask.tokenizer.mask_token\n",
    "            masked_string = ' '.join(input_string_list)\n",
    "            # print(masked_string)\n",
    "            \n",
    "            # Get results\n",
    "            results = fill_mask(masked_string, top_k=20)\n",
    "\n",
    "            # Token string dict\n",
    "            token_string_dict = {}\n",
    "\n",
    "            # Get top results and their score\n",
    "            for result in results:\n",
    "                try:\n",
    "                    token_string_dict[result[\"token_str\"]] = result[\"score\"]\n",
    "                except TypeError:\n",
    "                    # print(result)\n",
    "                    pass\n",
    "\n",
    "            # Sort results\n",
    "            sorted_results = sorted(token_string_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "            # Find top homophone in results\n",
    "            homophone_results = [result for result in sorted_results if result[0] in homophone_options[0]]\n",
    "            # print(homophone_results)\n",
    "            \n",
    "            # If the top result is the target homophone, return the original sentence as it is correct\n",
    "            try:\n",
    "                top_result = homophone_results[0][0]\n",
    "            except IndexError:\n",
    "                final_sentence.append(input_string)\n",
    "                is_error.append(False)\n",
    "                correct_word.append(None)\n",
    "                error_idx.append(None)\n",
    "                error.append(None)\n",
    "                continue\n",
    "\n",
    "            if top_result == target_homophone:\n",
    "                final_sentence.append(input_string)\n",
    "                is_error.append(False)\n",
    "                correct_word.append(None)\n",
    "                error_idx.append(None)\n",
    "                error.append(None)\n",
    "\n",
    "            else:\n",
    "                # If the top result is not the target homophone, check how many options it found\n",
    "                # If multiple options:\n",
    "                if len(homophone_results) > 1:\n",
    "\n",
    "                    # Check the difference between the top two results\n",
    "                    score_diff = homophone_results[0][1] - homophone_results[1][1]\n",
    "\n",
    "                    # If the difference is greater than the threshold, return the top result\n",
    "                    if score_diff > score_threshold:\n",
    "                        error_idx.append(input_string.split(\" \").index(target_homophone))\n",
    "                        error.append(target_homophone)\n",
    "                        final_sentence.append(input_string.replace(target_homophone, homophone_results[0][0]))\n",
    "                        correct_word.append(homophone_results[0][0])\n",
    "                        is_error.append(True)\n",
    "\n",
    "                        total_sentence = total_sentence.replace(target_homophone, homophone_results[0][0])\n",
    "                \n",
    "                # If the difference is less than the threshold, return the original sentence\n",
    "                else:\n",
    "                    is_error.append(True)\n",
    "                    error_idx.append(input_string.split(\" \").index(target_homophone))\n",
    "                    final_sentence.append(input_string.replace(target_homophone, homophone_results[0][0]))\n",
    "                    correct_word.append(homophone_results[0][0])\n",
    "                    error.append(target_homophone)\n",
    "\n",
    "                    total_sentence = total_sentence.replace(target_homophone, homophone_results[0][0])\n",
    "\n",
    "        # Create output dataframe that matches our test data\n",
    "        output_df = pd.DataFrame(\n",
    "                {\n",
    "                    \"sentence\": input_string,\n",
    "                    \"has_homophone\": True,\n",
    "                    \"is_error\": is_error,\n",
    "                    \"error_idx\": error_idx,\n",
    "                    \"error\": error,\n",
    "                    \"correct_word\": correct_word,\n",
    "                    \"correct_sentence\": final_sentence,\n",
    "                }, index=range(len(target_homophones))\n",
    "            )\n",
    "\n",
    "        print(total_sentence)\n",
    "        return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I drove to the restaurant to get some food but I ate way too much.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>has_homophone</th>\n",
       "      <th>is_error</th>\n",
       "      <th>error_idx</th>\n",
       "      <th>error</th>\n",
       "      <th>correct_word</th>\n",
       "      <th>correct_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i drove to the restaurant to get some food but...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>i drove to the restaurant to get some food but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i drove to the restaurant to get some food but...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>i drove to the restaurant to get some food but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i drove to the restaurant to get some food but...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>11.0</td>\n",
       "      <td>eight</td>\n",
       "      <td>ate</td>\n",
       "      <td>i drove to the restaurant to get some food but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i drove to the restaurant to get some food but...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>i drove to the restaurant to get some food but...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  has_homophone  is_error  \\\n",
       "0  i drove to the restaurant to get some food but...           True     False   \n",
       "1  i drove to the restaurant to get some food but...           True     False   \n",
       "2  i drove to the restaurant to get some food but...           True      True   \n",
       "3  i drove to the restaurant to get some food but...           True     False   \n",
       "\n",
       "   error_idx  error correct_word  \\\n",
       "0        NaN   None         None   \n",
       "1        NaN   None         None   \n",
       "2       11.0  eight          ate   \n",
       "3        NaN   None         None   \n",
       "\n",
       "                                    correct_sentence  \n",
       "0  i drove to the restaurant to get some food but...  \n",
       "1  i drove to the restaurant to get some food but...  \n",
       "2  i drove to the restaurant to get some food but...  \n",
       "3  i drove to the restaurant to get some food but...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homophone_checker(\"I drove to the restaurant to get some food but I eight way too much.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:26<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We hold these truths to be self-evident, that all men are created equal, that they are endowed by their Creator with certain unalienable Rights, that among these are Life, Liberty and the pursuit of Happiness.--That to secure these rights, Governments are instituted among Men, deriving their just powers from the consent of the governed, --That whenever any Form of Government becomes destructive of these ends, it is the Right of the People to alter or to abolish it, and to institute new Government, laying its foundation on such principles and organizing its powers in such form, as to them shall seem most likely to affect their Safety and Happiness. Prudence, indeed, will dictate that Governments long established should not be changed for light and transient causes; and accordingly all experience hath shewn, that mankind are more disposed to suffer, while evils are sufferable, than to right themselves by abolishing the forms to which they are accustomed. But when a long train of abuses and usurpations, pursuing invariably the same Object evinces a design to reduce them under absolute Despotism, it is their right, it is their duty, to throw off such Government, and to provide new Guards for their future security.--Such has been the patient sufferance of these Colonies; and such is now the necessity which constrains them to alter their former Systems of Government. The history of the present King of Great Britain is a history of repeated injuries and usurpations, all having in direct object the establishment of an absolute Tyranny over these States. To prove this, let Facts be submitted to a candid world.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>has_homophone</th>\n",
       "      <th>is_error</th>\n",
       "      <th>error_idx</th>\n",
       "      <th>error</th>\n",
       "      <th>correct_word</th>\n",
       "      <th>correct_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>104.0</td>\n",
       "      <td>effect</td>\n",
       "      <td>affect</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>137.0</td>\n",
       "      <td>too</td>\n",
       "      <td>to</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>we hold these truths to be self-evident, that ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  has_homophone  \\\n",
       "0   we hold these truths to be self-evident, that ...           True   \n",
       "1   we hold these truths to be self-evident, that ...           True   \n",
       "2   we hold these truths to be self-evident, that ...           True   \n",
       "3   we hold these truths to be self-evident, that ...           True   \n",
       "4   we hold these truths to be self-evident, that ...           True   \n",
       "5   we hold these truths to be self-evident, that ...           True   \n",
       "6   we hold these truths to be self-evident, that ...           True   \n",
       "7   we hold these truths to be self-evident, that ...           True   \n",
       "8   we hold these truths to be self-evident, that ...           True   \n",
       "9   we hold these truths to be self-evident, that ...           True   \n",
       "10  we hold these truths to be self-evident, that ...           True   \n",
       "11  we hold these truths to be self-evident, that ...           True   \n",
       "12  we hold these truths to be self-evident, that ...           True   \n",
       "13  we hold these truths to be self-evident, that ...           True   \n",
       "14  we hold these truths to be self-evident, that ...           True   \n",
       "15  we hold these truths to be self-evident, that ...           True   \n",
       "16  we hold these truths to be self-evident, that ...           True   \n",
       "17  we hold these truths to be self-evident, that ...           True   \n",
       "18  we hold these truths to be self-evident, that ...           True   \n",
       "19  we hold these truths to be self-evident, that ...           True   \n",
       "20  we hold these truths to be self-evident, that ...           True   \n",
       "21  we hold these truths to be self-evident, that ...           True   \n",
       "22  we hold these truths to be self-evident, that ...           True   \n",
       "23  we hold these truths to be self-evident, that ...           True   \n",
       "24  we hold these truths to be self-evident, that ...           True   \n",
       "25  we hold these truths to be self-evident, that ...           True   \n",
       "26  we hold these truths to be self-evident, that ...           True   \n",
       "27  we hold these truths to be self-evident, that ...           True   \n",
       "28  we hold these truths to be self-evident, that ...           True   \n",
       "29  we hold these truths to be self-evident, that ...           True   \n",
       "30  we hold these truths to be self-evident, that ...           True   \n",
       "31  we hold these truths to be self-evident, that ...           True   \n",
       "32  we hold these truths to be self-evident, that ...           True   \n",
       "33  we hold these truths to be self-evident, that ...           True   \n",
       "\n",
       "    is_error  error_idx   error correct_word  \\\n",
       "0      False        NaN    None         None   \n",
       "1      False        NaN    None         None   \n",
       "2      False        NaN    None         None   \n",
       "3      False        NaN    None         None   \n",
       "4      False        NaN    None         None   \n",
       "5      False        NaN    None         None   \n",
       "6      False        NaN    None         None   \n",
       "7      False        NaN    None         None   \n",
       "8      False        NaN    None         None   \n",
       "9      False        NaN    None         None   \n",
       "10     False        NaN    None         None   \n",
       "11     False        NaN    None         None   \n",
       "12      True      104.0  effect       affect   \n",
       "13     False        NaN    None         None   \n",
       "14     False        NaN    None         None   \n",
       "15      True      137.0     too           to   \n",
       "16     False        NaN    None         None   \n",
       "17     False        NaN    None         None   \n",
       "18     False        NaN    None         None   \n",
       "19     False        NaN    None         None   \n",
       "20     False        NaN    None         None   \n",
       "21     False        NaN    None         None   \n",
       "22     False        NaN    None         None   \n",
       "23     False        NaN    None         None   \n",
       "24     False        NaN    None         None   \n",
       "25     False        NaN    None         None   \n",
       "26     False        NaN    None         None   \n",
       "27     False        NaN    None         None   \n",
       "28     False        NaN    None         None   \n",
       "29     False        NaN    None         None   \n",
       "30     False        NaN    None         None   \n",
       "31     False        NaN    None         None   \n",
       "32     False        NaN    None         None   \n",
       "33     False        NaN    None         None   \n",
       "\n",
       "                                     correct_sentence  \n",
       "0   we hold these truths to be self-evident, that ...  \n",
       "1   we hold these truths to be self-evident, that ...  \n",
       "2   we hold these truths to be self-evident, that ...  \n",
       "3   we hold these truths to be self-evident, that ...  \n",
       "4   we hold these truths to be self-evident, that ...  \n",
       "5   we hold these truths to be self-evident, that ...  \n",
       "6   we hold these truths to be self-evident, that ...  \n",
       "7   we hold these truths to be self-evident, that ...  \n",
       "8   we hold these truths to be self-evident, that ...  \n",
       "9   we hold these truths to be self-evident, that ...  \n",
       "10  we hold these truths to be self-evident, that ...  \n",
       "11  we hold these truths to be self-evident, that ...  \n",
       "12  we hold these truths to be self-evident, that ...  \n",
       "13  we hold these truths to be self-evident, that ...  \n",
       "14  we hold these truths to be self-evident, that ...  \n",
       "15  we hold these truths to be self-evident, that ...  \n",
       "16  we hold these truths to be self-evident, that ...  \n",
       "17  we hold these truths to be self-evident, that ...  \n",
       "18  we hold these truths to be self-evident, that ...  \n",
       "19  we hold these truths to be self-evident, that ...  \n",
       "20  we hold these truths to be self-evident, that ...  \n",
       "21  we hold these truths to be self-evident, that ...  \n",
       "22  we hold these truths to be self-evident, that ...  \n",
       "23  we hold these truths to be self-evident, that ...  \n",
       "24  we hold these truths to be self-evident, that ...  \n",
       "25  we hold these truths to be self-evident, that ...  \n",
       "26  we hold these truths to be self-evident, that ...  \n",
       "27  we hold these truths to be self-evident, that ...  \n",
       "28  we hold these truths to be self-evident, that ...  \n",
       "29  we hold these truths to be self-evident, that ...  \n",
       "30  we hold these truths to be self-evident, that ...  \n",
       "31  we hold these truths to be self-evident, that ...  \n",
       "32  we hold these truths to be self-evident, that ...  \n",
       "33  we hold these truths to be self-evident, that ...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homophone_checker(\"We hold these truths to be self-evident, that all men are created equal, that they are endowed by their Creator with certain unalienable Rights, that among these are Life, Liberty and the pursuit of Happiness.--That to secure these rights, Governments are instituted among Men, deriving their just powers from the consent of the governed, --That whenever any Form of Government becomes destructive of these ends, it is the Right of the People to alter or to abolish it, and to institute new Government, laying its foundation on such principles and organizing its powers in such form, as to them shall seem most likely to effect their Safety and Happiness. Prudence, indeed, will dictate that Governments long established should not be changed for light and transient causes; and accordingly all experience hath shewn, that mankind are more disposed too suffer, while evils are sufferable, than to right themselves by abolishing the forms to which they are accustomed. But when a long train of abuses and usurpations, pursuing invariably the same Object evinces a design to reduce them under absolute Despotism, it is their right, it is their duty, to throw off such Government, and to provide new Guards for their future security.--Such has been the patient sufferance of these Colonies; and such is now the necessity which constrains them to alter their former Systems of Government. The history of the present King of Great Britain is a history of repeated injuries and usurpations, all having in direct object the establishment of an absolute Tyranny over these States. To prove this, let Facts be submitted to a candid world.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct but slow. I added the wrong \"too\" and the affect one is close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>has_homophone</th>\n",
       "      <th>is_error</th>\n",
       "      <th>error_idx</th>\n",
       "      <th>error</th>\n",
       "      <th>correct_word</th>\n",
       "      <th>correct_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>natural language processing (nlp) lies at the ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>natural language processing (nlp) lies at the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>natural language processing (nlp) lies at the ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>natural language processing (nlp) lies at the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  has_homophone  is_error  \\\n",
       "0  natural language processing (nlp) lies at the ...           True     False   \n",
       "1  natural language processing (nlp) lies at the ...           True     False   \n",
       "\n",
       "  error_idx error correct_word  \\\n",
       "0      None  None         None   \n",
       "1      None  None         None   \n",
       "\n",
       "                                    correct_sentence  \n",
       "0  natural language processing (nlp) lies at the ...  \n",
       "1  natural language processing (nlp) lies at the ...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homophone_checker(\"Natural language processing (NLP) lies at the heart of modern information systems. The rate of advancement in the field is measurably exponential; in the last 30 years it has transformed how humans acquire knowledge and interact with computers, multiple times. This course traces these advancements through the lens of the statistical machine learning methods that have enabled them. We explore how language understanding is framed as a tractable inference problem through language modeling, and the model architectures and algorithms that have proven most successful in real world applications. This course assumes a basic understanding of linear algebra, probability theory, and first order optimization methods.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>has_homophone</th>\n",
       "      <th>is_error</th>\n",
       "      <th>error_idx</th>\n",
       "      <th>error</th>\n",
       "      <th>correct_word</th>\n",
       "      <th>correct_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>natural language processing (nlp) lies at the ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>natural language processing (nlp) lies at the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>natural language processing (nlp) lies at the ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>70.0</td>\n",
       "      <td>threw</td>\n",
       "      <td>through</td>\n",
       "      <td>natural language processing (nlp) lies at the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  has_homophone  is_error  \\\n",
       "0  natural language processing (nlp) lies at the ...           True     False   \n",
       "1  natural language processing (nlp) lies at the ...           True      True   \n",
       "\n",
       "   error_idx  error correct_word  \\\n",
       "0        NaN   None         None   \n",
       "1       70.0  threw      through   \n",
       "\n",
       "                                    correct_sentence  \n",
       "0  natural language processing (nlp) lies at the ...  \n",
       "1  natural language processing (nlp) lies at the ...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changed \"through\" to \"threw\"\n",
    "homophone_checker(\"Natural language processing (NLP) lies at the heart of modern information systems. The rate of advancement in the field is measurably exponential; in the last 30 years it has transformed how humans acquire knowledge and interact with computers, multiple times. This course traces these advancements through the lens of the statistical machine learning methods that have enabled them. We explore how language understanding is framed as a tractable inference problem threw language modeling, and the model architectures and algorithms that have proven most successful in real world applications. This course assumes a basic understanding of linear algebra, probability theory, and first order optimization methods.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/14 [00:00<00:10,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('all', 0.9307690262794495)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 2/14 [00:01<00:06,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('due', 0.058565735816955566)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 3/14 [00:01<00:05,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('you', 0.005640147719532251)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 4/14 [00:02<00:04,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to', 0.9996193647384644), ('too', 5.555410780289094e-07)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 5/14 [00:02<00:04,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to', 0.978023111820221), ('two', 1.1868312412843807e-06)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 6/14 [00:02<00:03,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dew', 0.9527957439422607), ('due', 0.005295096430927515)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 7/14 [00:03<00:03,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to', 0.999119222164154), ('too', 7.347837254201295e-07)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 8/14 [00:03<00:02,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('all', 0.7756891250610352)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 9/14 [00:04<00:02,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to', 0.9939383268356323), ('too', 6.319897920548101e-07)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 10/14 [00:04<00:01,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('you', 0.999502420425415)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 11/14 [00:05<00:01,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to', 0.9998379945755005)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 12/14 [00:05<00:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('you', 0.9949028491973877)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 13/14 [00:05<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to', 0.9436678290367126), ('too', 3.871240551234223e-06)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:06<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('due', 0.9452741146087646)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>has_homophone</th>\n",
       "      <th>is_error</th>\n",
       "      <th>error_idx</th>\n",
       "      <th>error</th>\n",
       "      <th>correct_word</th>\n",
       "      <th>correct_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "      <td>due</td>\n",
       "      <td>dew</td>\n",
       "      <td>late policy: all submissions are dew 11:59pm e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>115.0</td>\n",
       "      <td>dew</td>\n",
       "      <td>due</td>\n",
       "      <td>late policy: all submissions are due 11:59pm e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  has_homophone  \\\n",
       "0   late policy: all submissions are due 11:59pm e...           True   \n",
       "1   late policy: all submissions are due 11:59pm e...           True   \n",
       "2   late policy: all submissions are due 11:59pm e...           True   \n",
       "3   late policy: all submissions are due 11:59pm e...           True   \n",
       "4   late policy: all submissions are due 11:59pm e...           True   \n",
       "5   late policy: all submissions are due 11:59pm e...           True   \n",
       "6   late policy: all submissions are due 11:59pm e...           True   \n",
       "7   late policy: all submissions are due 11:59pm e...           True   \n",
       "8   late policy: all submissions are due 11:59pm e...           True   \n",
       "9   late policy: all submissions are due 11:59pm e...           True   \n",
       "10  late policy: all submissions are due 11:59pm e...           True   \n",
       "11  late policy: all submissions are due 11:59pm e...           True   \n",
       "12  late policy: all submissions are due 11:59pm e...           True   \n",
       "13  late policy: all submissions are due 11:59pm e...           True   \n",
       "\n",
       "    is_error  error_idx error correct_word  \\\n",
       "0      False        NaN  None         None   \n",
       "1      False        NaN  None         None   \n",
       "2      False        NaN  None         None   \n",
       "3      False        NaN  None         None   \n",
       "4      False        NaN  None         None   \n",
       "5       True        5.0   due          dew   \n",
       "6      False        NaN  None         None   \n",
       "7      False        NaN  None         None   \n",
       "8      False        NaN  None         None   \n",
       "9      False        NaN  None         None   \n",
       "10     False        NaN  None         None   \n",
       "11     False        NaN  None         None   \n",
       "12     False        NaN  None         None   \n",
       "13      True      115.0   dew          due   \n",
       "\n",
       "                                     correct_sentence  \n",
       "0   late policy: all submissions are due 11:59pm e...  \n",
       "1   late policy: all submissions are due 11:59pm e...  \n",
       "2   late policy: all submissions are due 11:59pm e...  \n",
       "3   late policy: all submissions are due 11:59pm e...  \n",
       "4   late policy: all submissions are due 11:59pm e...  \n",
       "5   late policy: all submissions are dew 11:59pm e...  \n",
       "6   late policy: all submissions are due 11:59pm e...  \n",
       "7   late policy: all submissions are due 11:59pm e...  \n",
       "8   late policy: all submissions are due 11:59pm e...  \n",
       "9   late policy: all submissions are due 11:59pm e...  \n",
       "10  late policy: all submissions are due 11:59pm e...  \n",
       "11  late policy: all submissions are due 11:59pm e...  \n",
       "12  late policy: all submissions are due 11:59pm e...  \n",
       "13  late policy: all submissions are due 11:59pm e...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change \"due\" to \"dew\" in last sentence\n",
    "homophone_checker(\"Late Policy: All submissions are due 11:59pm EST on the dates listed. You are free to submit work up to 7 days after the due date, subject to the following: All submissions will be assigned a score equal to the higher of (a) the grade of the on-time submission, and (b) the grade of the late submission with a 20% deduction. As an example, if you were to receive an 79% on a lab, and then submit changes with corrections within the 7 day window resulting in a revised nominal score of 100%, you will receive a grade of 80% for that lab. Importantly, this late policy does not apply to the final project; the dew date for final project submissions will be strictly enforced.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found my change but also wrongly changed one earlier; I think we will need to add a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to', 0.5008355975151062)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to', 0.4922170639038086)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>has_homophone</th>\n",
       "      <th>is_error</th>\n",
       "      <th>error_idx</th>\n",
       "      <th>error</th>\n",
       "      <th>correct_word</th>\n",
       "      <th>correct_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>considering meta’s strategic shift too the met...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>too</td>\n",
       "      <td>to</td>\n",
       "      <td>considering meta’s strategic shift to the meta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>considering meta’s strategic shift too the met...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>considering meta’s strategic shift too the met...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  has_homophone  is_error  \\\n",
       "0  considering meta’s strategic shift too the met...           True      True   \n",
       "1  considering meta’s strategic shift too the met...           True     False   \n",
       "\n",
       "   error_idx error correct_word  \\\n",
       "0        4.0   too           to   \n",
       "1        NaN  None         None   \n",
       "\n",
       "                                    correct_sentence  \n",
       "0  considering meta’s strategic shift to the meta...  \n",
       "1  considering meta’s strategic shift too the met...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homophone_checker(\"Considering Meta’s strategic shift too the metaverse, encompassing Facebook’s social media and related services, the current vision statement accurately represents the business and its operations. On the other hand, the mission statement remains focused on building connections. These factors indicate that the corporate mission and vision statements guide Facebook’s (Meta’s) operations management to support business growth based on the metaverse.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to', 0.9995779395103455)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>has_homophone</th>\n",
       "      <th>is_error</th>\n",
       "      <th>error_idx</th>\n",
       "      <th>error</th>\n",
       "      <th>correct_word</th>\n",
       "      <th>correct_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rudolph the red-nosed reindeer is a fictional ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>rudolph the red-nosed reindeer is a fictional ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  has_homophone  is_error  \\\n",
       "0  rudolph the red-nosed reindeer is a fictional ...           True     False   \n",
       "\n",
       "  error_idx error correct_word  \\\n",
       "0      None  None         None   \n",
       "\n",
       "                                    correct_sentence  \n",
       "0  rudolph the red-nosed reindeer is a fictional ...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changed \"sleigh\" to \"slay\"\n",
    "homophone_checker(\"Rudolph the Red-Nosed Reindeer is a fictional reindeer created by Robert L. May. Rudolph is usually depicted as the ninth and youngest of Santa Claus's reindeer, using his luminous red nose to lead the reindeer team and guide Santa's slay on Christmas Eve.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undetected; our homophone list is too short."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3aa3b34c753eef143aae9642862cd7fbbae789492df1e9a732d4626a6da5afce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
