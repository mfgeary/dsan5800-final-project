{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: regex in /Users/Austin/opt/anaconda3/envs/torch/lib/python3.10/site-packages (from sacremoses) (2022.10.31)\n",
      "Requirement already satisfied: click in /Users/Austin/opt/anaconda3/envs/torch/lib/python3.10/site-packages (from sacremoses) (8.1.3)\n",
      "Requirement already satisfied: joblib in /Users/Austin/opt/anaconda3/envs/torch/lib/python3.10/site-packages (from sacremoses) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /Users/Austin/opt/anaconda3/envs/torch/lib/python3.10/site-packages (from sacremoses) (4.65.0)\n",
      "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sacremoses\n",
      "Successfully installed sacremoses-0.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sacremoses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homophone List\n",
    "\n",
    "This needs to be expanded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat GPT Prompt: Give me a list of lists in python of 100 sets of homophones\n",
    "homophones_list = [\n",
    "    [\"ate\", \"eight\"],\n",
    "    [\"bare\", \"bear\"],\n",
    "    [\"brake\", \"break\"],\n",
    "    [\"capital\", \"capitol\"],\n",
    "    [\"cell\", \"sell\"],\n",
    "    [\"cite\", \"site\", \"sight\"],\n",
    "    [\"complement\", \"compliment\"],\n",
    "    [\"desert\", \"dessert\"],\n",
    "    [\"die\", \"dye\"],\n",
    "    [\"flour\", \"flower\"],\n",
    "    [\"hear\", \"here\"],\n",
    "    [\"hour\", \"our\"],\n",
    "    [\"knight\", \"night\"],\n",
    "    [\"know\", \"no\"],\n",
    "    [\"mail\", \"male\"],\n",
    "    [\"meat\", \"meet\"],\n",
    "    [\"morning\", \"mourning\"],\n",
    "    [\"one\", \"won\"],\n",
    "    [\"pair\", \"pear\"],\n",
    "    [\"peace\", \"piece\"],\n",
    "    [\"principal\", \"principle\"],\n",
    "    [\"rain\", \"reign\", \"rein\"],\n",
    "    [\"right\", \"write\"],\n",
    "    [\"sea\", \"see\"],\n",
    "    [\"serial\", \"cereal\"],\n",
    "    [\"sole\", \"soul\"],\n",
    "    [\"stationary\", \"stationery\"],\n",
    "    [\"tail\", \"tale\"],\n",
    "    [\"threw\", \"through\"],\n",
    "    [\"to\", \"too\", \"two\"],\n",
    "    [\"weather\", \"whether\"],\n",
    "    [\"week\", \"weak\"],\n",
    "    [\"wear\", \"where\"],\n",
    "    [\"which\", \"witch\"],\n",
    "    [\"your\", \"you're\"],\n",
    "    [\"allowed\", \"aloud\"],\n",
    "    [\"board\", \"bored\"],\n",
    "    [\"brake\", \"break\"],\n",
    "    [\"capital\", \"capitol\"],\n",
    "    [\"compliment\", \"complement\"],\n",
    "    [\"desert\", \"dessert\"],\n",
    "    [\"dual\", \"duel\"],\n",
    "    [\"fair\", \"fare\"],\n",
    "    [\"genre\", \"jinja\"],\n",
    "    [\"hare\", \"hair\"],\n",
    "    [\"here\", \"hear\"],\n",
    "    [\"hoard\", \"horde\"],\n",
    "    [\"loan\", \"lone\"],\n",
    "    [\"pail\", \"pale\"],\n",
    "    [\"peak\", \"peek\", \"pique\"],\n",
    "    [\"profit\", \"prophet\"],\n",
    "    [\"role\", \"roll\"],\n",
    "    [\"root\", \"route\"],\n",
    "    [\"sail\", \"sale\"],\n",
    "    [\"scene\", \"seen\"],\n",
    "    [\"serial\", \"cereal\"],\n",
    "    [\"so\", \"sow\"],\n",
    "    [\"stare\", \"stair\"],\n",
    "    [\"steal\", \"steel\"],\n",
    "    [\"their\", \"there\", \"they're\"],\n",
    "    [\"throne\", \"thrown\"],\n",
    "    [\"vain\", \"vein\", \"vane\"],\n",
    "    [\"weak\", \"week\"],\n",
    "    [\"wood\", \"would\"],\n",
    "    [\"yew\", \"you\"],\n",
    "    [\"bridal\", \"bridle\"],\n",
    "    [\"cereal\", \"serial\"],\n",
    "    [\"chord\", \"cord\"],\n",
    "    [\"compliment\", \"complement\"],\n",
    "    [\"dew\", \"due\"],\n",
    "    [\"foul\", \"fowl\"],\n",
    "    [\"grate\", \"great\"],\n",
    "    [\"groan\", \"grown\"],\n",
    "    [\"heal\", \"heel\"],\n",
    "    [\"him\", \"hymn\"],\n",
    "    [\"lay\", \"lie\"],\n",
    "    [\"main\", \"mane\"],\n",
    "    [\"marry\", \"merry\"],\n",
    "    [\"mite\", \"might\"],\n",
    "    [\"moose\", \"mousse\"],\n",
    "    [\"mourn\", \"morn\"],\n",
    "    [\"peace\", \"piece\"],\n",
    "    [\"plum\", \"plumb\"],\n",
    "    [\"pour\", \"pore\"],\n",
    "    [\"rap\", \"wrap\"],\n",
    "    [\"scene\", \"seen\"],\n",
    "    [\"scent\", \"cent\", \"sent\"],\n",
    "    [\"serial\", \"cereal\"],\n",
    "    [\"shear\", \"sheer\"],\n",
    "    [\"soar\", \"sore\"],\n",
    "    [\"sow\", \"sew\"],\n",
    "    [\"stake\", \"steak\"],\n",
    "    [\"tide\", \"tied\"],\n",
    "    [\"toe\", \"tow\"],\n",
    "    [\"there\", \"their\", \"they're\"],\n",
    "    [\"waist\", \"waste\"],\n",
    "    [\"week\", \"weak\"],\n",
    "    [\"write\", \"right\", \"rite\"],\n",
    "    [\"won\", \"one\"],\n",
    "    [\"your\", \"you're\"],\n",
    "    [\"dear\", \"deer\"],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model\n",
    "\n",
    "Bert has been working decently well for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the model and tokenizer\n",
    "fill_mask = pipeline('fill-mask', model='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect!\n",
      "Top result:  won\n",
      "Top result score:  0.704522430896759\n"
     ]
    }
   ],
   "source": [
    "# Create input string\n",
    "input_string = \"Michigan one the football game against Ohio State!\"\n",
    "\n",
    "# Select homophone\n",
    "target_homophone = \"one\"\n",
    "\n",
    "# Get homophone options\n",
    "homophone_options = [homophone for homophone in homophones_list if target_homophone in homophone]\n",
    "\n",
    "# Replace homophone with mask token\n",
    "input_string = input_string.replace(target_homophone, fill_mask.tokenizer.mask_token)\n",
    "\n",
    "# Get results\n",
    "results = fill_mask(input_string)\n",
    "\n",
    "# Token string dict\n",
    "token_string_dict = {}\n",
    "\n",
    "# Get top results\n",
    "for result in results:\n",
    "   token_string_dict[result[\"token_str\"]] = result[\"score\"]\n",
    "\n",
    "# Sort results\n",
    "sorted_results = sorted(token_string_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Find top homophone in results\n",
    "homophone_results = [result for result in sorted_results if result[0] in homophone_options[0]]\n",
    "\n",
    "if homophone_results[0][0] == target_homophone:\n",
    "    print(\"Correct!\")\n",
    "else:\n",
    "    print(\"Incorrect!\")\n",
    "    print(\"Top result: \", homophone_results[0][0])\n",
    "    print(\"Top result score: \", homophone_results[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that can check a sentence that only contains one homophone\n",
    "def one_homophone_checker(input_string, homophones_list=homophones_list, score_threshold=0):\n",
    "    # Lowering the input string\n",
    "    input_string = input_string.lower()\n",
    "\n",
    "    # Flatten homophones list\n",
    "    all_homophones = [\n",
    "        word for homophone_set in homophones_list for word in homophone_set\n",
    "    ]\n",
    "\n",
    "    # Find homophones in input string\n",
    "    target_homophone = list(set(input_string.split(\" \")).intersection(set(all_homophones)))\n",
    "    print(target_homophone)\n",
    "\n",
    "    # If there are no homophones in the sentence, return the NA dataframe\n",
    "    if len(target_homophone) < 1:\n",
    "        output_df = pd.DataFrame(\n",
    "            {\n",
    "                \"sentence\": input_string,\n",
    "                \"has_homophone\": False,\n",
    "                \"is_error\": None,\n",
    "                \"error_idx\": None,\n",
    "                \"error\": None,\n",
    "                \"correct_word\": None,\n",
    "                \"correct_sentence\": None,\n",
    "            }, index=[0]\n",
    "        )\n",
    "        return output_df\n",
    "\n",
    "    else:\n",
    "        target_homophone = target_homophone[0]\n",
    "\n",
    "    # Get all homophone options from homophones list\n",
    "    homophone_options = [homophone for homophone in homophones_list if target_homophone in homophone]\n",
    "\n",
    "    # Replace homophone with mask token\n",
    "    # CANNOT HANDLE MULTIPLE HOMOPHONES IN ONE SENTENCE\n",
    "    masked_string = ' '.join([word if word != target_homophone else fill_mask.tokenizer.mask_token for word in input_string.split(\" \")])\n",
    "    print(masked_string)\n",
    "    \n",
    "    # Get results\n",
    "    results = fill_mask(masked_string, top_k=100)\n",
    "\n",
    "    # Token string dict\n",
    "    token_string_dict = {}\n",
    "\n",
    "    # Get top results and their score\n",
    "    for result in results:\n",
    "        try:\n",
    "            token_string_dict[result[\"token_str\"]] = result[\"score\"]\n",
    "        except TypeError:\n",
    "            print(result)\n",
    "\n",
    "    # Sort results\n",
    "    sorted_results = sorted(token_string_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Find top homophone in results\n",
    "    homophone_results = [result for result in sorted_results if result[0] in homophone_options[0]]\n",
    "    print(homophone_results)\n",
    "    \n",
    "    # If the top result is the target homophone, return the original sentence as it is correct\n",
    "    if homophone_results[0][0] == target_homophone:\n",
    "        final_sentence = input_string\n",
    "        is_error = False\n",
    "        correct_word = None\n",
    "        error_idx = None\n",
    "        error = None\n",
    "\n",
    "    else:\n",
    "        # If the top result is not the target homophone, check how many options it found\n",
    "        # If multiple options:\n",
    "        if len(homophone_results) > 1:\n",
    "\n",
    "            # Check the difference between the top two results\n",
    "            score_diff = homophone_results[0][1] - homophone_results[1][1]\n",
    "\n",
    "            # If the difference is greater than the threshold, return the top result\n",
    "            if score_diff > score_threshold:\n",
    "                error_idx = input_string.split(\" \").index(target_homophone)\n",
    "                error = target_homophone\n",
    "                final_sentence = input_string.replace(target_homophone, homophone_results[0][0])\n",
    "                correct_word = homophone_results[0][0]\n",
    "                is_error = True\n",
    "        \n",
    "        # If the difference is less than the threshold, return the original sentence\n",
    "        else:\n",
    "            is_error = True\n",
    "            error_idx = input_string.split(\" \").index(target_homophone)\n",
    "            final_sentence = input_string.replace(target_homophone, homophone_results[0][0])\n",
    "            correct_word = homophone_results[0][0]\n",
    "            error = target_homophone\n",
    "\n",
    "    # Create output dataframe that matches our test data\n",
    "    output_df = pd.DataFrame(\n",
    "            {\n",
    "                \"sentence\": input_string,\n",
    "                \"has_homophone\": True,\n",
    "                \"is_error\": is_error,\n",
    "                \"error_idx\": error_idx,\n",
    "                \"error\": error,\n",
    "                \"correct_word\": correct_word,\n",
    "                \"correct_sentence\": final_sentence,\n",
    "            }, index=[0]\n",
    "        )\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to']\n",
      "at lunch today, i had way [MASK] much food!\n",
      "[('too', 0.9997673630714417), ('to', 4.6690133785887156e-06)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>has_homophone</th>\n",
       "      <th>is_error</th>\n",
       "      <th>error_idx</th>\n",
       "      <th>error</th>\n",
       "      <th>correct_word</th>\n",
       "      <th>correct_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>at lunch today, i had way to much food!</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>to</td>\n",
       "      <td>too</td>\n",
       "      <td>at lunch tooday, i had way too much food!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  sentence  has_homophone  is_error  \\\n",
       "0  at lunch today, i had way to much food!           True      True   \n",
       "\n",
       "   error_idx error correct_word                           correct_sentence  \n",
       "0          6    to          too  at lunch tooday, i had way too much food!  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_string = \"At lunch today, I had way to much food!\"\n",
    "\n",
    "one_homophone_checker(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one']\n",
      "michigan [MASK] the game against ohio state!\n",
      "[('won', 0.7407358884811401)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>has_homophone</th>\n",
       "      <th>is_error</th>\n",
       "      <th>error_idx</th>\n",
       "      <th>error</th>\n",
       "      <th>correct_word</th>\n",
       "      <th>correct_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>michigan one the game against ohio state!</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>won</td>\n",
       "      <td>michigan won the game against ohio state!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    sentence  has_homophone  is_error  \\\n",
       "0  michigan one the game against ohio state!           True      True   \n",
       "\n",
       "   error_idx error correct_word                           correct_sentence  \n",
       "0          1   one          won  michigan won the game against ohio state!  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_string = \"Michigan one the game against Ohio State!\"\n",
    "\n",
    "one_homophone_checker(input_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEXT STEPS: MAKE SENTENCES LIKE THIS WORK WITH MULTIPLE ERRORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['waist', 'scene', 'you']\n",
      "have you scene my new [MASK] of money?\n",
      "[('waste', 0.003929820377379656)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>has_homophone</th>\n",
       "      <th>is_error</th>\n",
       "      <th>error_idx</th>\n",
       "      <th>error</th>\n",
       "      <th>correct_word</th>\n",
       "      <th>correct_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>have you scene my new waist of money?</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>waist</td>\n",
       "      <td>waste</td>\n",
       "      <td>have you scene my new waste of money?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                sentence  has_homophone  is_error  error_idx  \\\n",
       "0  have you scene my new waist of money?           True      True          5   \n",
       "\n",
       "   error correct_word                       correct_sentence  \n",
       "0  waist        waste  have you scene my new waste of money?  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_string = \"Have you scene my new waist of money?\"\n",
    "\n",
    "one_homophone_checker(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3aa3b34c753eef143aae9642862cd7fbbae789492df1e9a732d4626a6da5afce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
